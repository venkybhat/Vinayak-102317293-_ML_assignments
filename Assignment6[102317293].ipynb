{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. (Gaussian Naïve Bayes Classifier) Implement Gaussian Naïve Bayes\n",
        "Classifier on the Iris dataset from sklearn.datasets using\n",
        "(i) Step-by-step implementation\n",
        "(ii) In-built function"
      ],
      "metadata": {
        "id": "EYpcy0EbC2sd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTW4IoQFC2Av",
        "outputId": "327330db-7f32-427c-ed10-0de8e4f2c07a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Gaussian Naive Bayes accuracy: 0.9777777777777777\n"
          ]
        }
      ],
      "source": [
        "#1(i)\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris_bunch = datasets.load_iris()\n",
        "flowers_data = iris_bunch.data\n",
        "flowers_labels = iris_bunch.target\n",
        "\n",
        "\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(\n",
        "    flowers_data, flowers_labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_my_gaussian_nb(train_x, train_y):\n",
        "    class_list = np.unique(train_y)\n",
        "\n",
        "\n",
        "    mean_dict = {}\n",
        "    var_dict = {}\n",
        "    prior_dict = {}\n",
        "\n",
        "    for cls in class_list:\n",
        "\n",
        "        cls_rows = train_x[train_y == cls]\n",
        "\n",
        "\n",
        "        mean_dict[cls] = np.mean(cls_rows, axis=0)\n",
        "        var_dict[cls] = np.var(cls_rows, axis=0) + 1e-6\n",
        "\n",
        "        prior_dict[cls] = cls_rows.shape[0] / float(train_x.shape[0])\n",
        "\n",
        "    return class_list, mean_dict, var_dict, prior_dict\n",
        "def my_gaussian_pdf(x_value, mean_value, var_value):\n",
        "    numerator = np.exp(- ((x_value - mean_value) ** 2) / (2 * var_value))\n",
        "    denominator = np.sqrt(2 * np.pi * var_value)\n",
        "    return numerator / denominator\n",
        "\n",
        "\n",
        "def predict_one_sample(sample_x, class_list, mean_dict, var_dict, prior_dict):\n",
        "    class_probabilities = {}\n",
        "\n",
        "    for cls in class_list:\n",
        "\n",
        "        log_prob = np.log(prior_dict[cls])\n",
        "        feature_means = mean_dict[cls]\n",
        "        feature_vars = var_dict[cls]\n",
        "\n",
        "\n",
        "        for j in range(len(sample_x)):\n",
        "            prob_ij = my_gaussian_pdf(sample_x[j], feature_means[j], feature_vars[j])\n",
        "            log_prob += np.log(prob_ij)\n",
        "\n",
        "        class_probabilities[cls] = log_prob\n",
        "\n",
        "\n",
        "    best_class = max(class_probabilities, key=class_probabilities.get)\n",
        "    return best_class\n",
        "\n",
        "\n",
        "def predict_my_gaussian_nb(test_x, class_list, mean_dict, var_dict, prior_dict):\n",
        "    all_predictions = []\n",
        "    for i in range(test_x.shape[0]):\n",
        "        one_pred = predict_one_sample(test_x[i], class_list, mean_dict, var_dict, prior_dict)\n",
        "        all_predictions.append(one_pred)\n",
        "    return np.array(all_predictions)\n",
        "\n",
        "\n",
        "class_list, mean_dict, var_dict, prior_dict = train_my_gaussian_nb(data_train, labels_train)\n",
        "\n",
        "\n",
        "manual_predictions = predict_my_gaussian_nb(data_test, class_list, mean_dict, var_dict, prior_dict)\n",
        "\n",
        "\n",
        "manual_accuracy = accuracy_score(labels_test, manual_predictions)\n",
        "print(\"Manual Gaussian Naive Bayes accuracy:\", manual_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "simple_gnb_model = GaussianNB()\n",
        "\n",
        "simple_gnb_model.fit(data_train, labels_train)\n",
        "\n",
        "\n",
        "sklearn_predictions = simple_gnb_model.predict(data_test)\n",
        "\n",
        "sklearn_accuracy = accuracy_score(labels_test, sklearn_predictions)\n",
        "print(\"Sklearn GaussianNB accuracy:\", sklearn_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeF2ve-jDw0_",
        "outputId": "159964ab-1864-4cf6-bb66-b0815054938a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn GaussianNB accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Explore about GridSearchCV toot in scikit-learn. This is a tool that is\n",
        "often used for tuning hyperparameters of machine learning models. Use\n",
        "this tool to find the best value of K for K-NN Classifier using any dataset."
      ],
      "metadata": {
        "id": "8LI8WOpDDUX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer_bunch = load_breast_cancer()\n",
        "x_stuff = cancer_bunch.data\n",
        "y_stuff = cancer_bunch.target\n",
        "\n",
        "\n",
        "x_train_part, x_test_part, y_train_part, y_test_part = train_test_split(\n",
        "    x_stuff,\n",
        "    y_stuff,\n",
        "    test_size=0.3,\n",
        "    random_state=5\n",
        ")\n",
        "\n",
        "\n",
        "knn_box = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "k_values_list = list(range(1, 21))\n",
        "grid_dictionary = {\n",
        "    'n_neighbors': k_values_list\n",
        "}\n",
        "\n",
        "\n",
        "grid_machine = GridSearchCV(\n",
        "    estimator=knn_box,\n",
        "    param_grid=grid_dictionary,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "grid_machine.fit(x_train_part, y_train_part)\n",
        "\n",
        "print(\"Best K value found:\", grid_machine.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_machine.best_score_)\n",
        "\n",
        "best_model_from_grid = grid_machine.best_estimator_\n",
        "y_test_predictions = best_model_from_grid.predict(x_test_part)\n",
        "\n",
        "\n",
        "final_test_accuracy = accuracy_score(y_test_part, y_test_predictions)\n",
        "print(\"Test accuracy with best K:\", final_test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjRZmcpXDWje",
        "outputId": "ae7f74e6-8bda-4377-cad6-121639eb7a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K value found: {'n_neighbors': 10}\n",
            "Best cross-validation accuracy: 0.9220569620253165\n",
            "Test accuracy with best K: 0.9766081871345029\n"
          ]
        }
      ]
    }
  ]
}